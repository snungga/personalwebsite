
[{"content":".\n","date":"1 March 2025","externalUrl":null,"permalink":"/","section":"","summary":".","title":"","type":"page"},{"content":"","date":"1 March 2025","externalUrl":null,"permalink":"/categories/blog/","section":"Categories","summary":"","title":"Blog","type":"categories"},{"content":"","date":"1 March 2025","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":" Introduction # In the world of geophysics, coordinates are typically the foundation of all measurements and interpretations. They allow geophysicists to map subsurface features, such as faults, reservoirs, and layers, with precision. But what if, for some reason, you don’t have access to coordinates? How do you make sense of the data, and can meaningful geophysical imaging still occur?\nThe short answer is yes, it’s possible — but it becomes much more complex and requires creative solutions. Let’s explore what happens when coordinates are unavailable and how geophysicists can work around this limitation.\nThe training will stop once the model reaches convergence, meaning the loss function is minimized to an acceptable level. If convergence is not achieved, the training process continues by further adjusting the model parameters.\nIn Imaging Seismic can have many problems such as :\nOffset (Near or Far offset) Static Corrections Velocity models NMO You can see the image to give informations for Shot Point (SP) but it\u0026rsquo;s many gaps starting from 128 , 130, 135 etc. Consinstenly gaps with approximately 4 example started from 130, 131, 132, 133, 134, 135 and without containing information coordinates. So we purpose to fill the gaps (n=4) using interpolations methods\nThe formula for linear interpolation between two data points \\((x_0, y_0)\\) and \\((x_1, y_1)\\) is given by:\n\\(y = y_0 + \\frac{(x - x_0)}{(x_1 - x_0)}(y_1 - y_0)\\)\n\\(y\\) is the interpolated value at \\(x\\), \\(x_0\\) and \\(x_1\\) are the known \\(x\\)-values, \\(y_0\\) and \\(y_1\\) are the known \\(y\\)-values, \\(x\\) is the input value where we want to estimate \\(y\\). However, we try with other interpolations with using Cubic Spline. Spline interpolation uses piecewise polynomials (typically cubic polynomials) to interpolate between data points. One common method is cubic spline interpolation, which fits a cubic polynomial between each pair of adjacent data points and ensures smoothness at the data point boundaries.\nSpline Interpolation: Spline interpolation fits a smooth curve between data points using piecewise polynomials. The most commonly used spline is the cubic spline, which uses cubic polynomials between each pair of adjacent data points.\nThe cubic spline equation for the segment between two data points \\((x_i, y_i)\\) and \\((x_{i+1}, y_{i+1})\\) is typically given by:\n\\[ S_i(x) = a_i(x - x_i)^3 + b_i(x - x_i)^2 + c_i(x - x_i) + d_i \\]\nWhere:\n\\(S_i(x)\\) is the cubic spline polynomial for the segment between the points \\((x_i, y_i)\\) and \\((x_{i+1}, y_{i+1})\\), \\(a_i, b_i, c_i, d_i\\) are the coefficients determined by solving a system of equations that ensures smoothness (continuous first and second derivatives) across adjacent segments. The goal of spline interpolation is to ensure that:\nThe spline is continuous at the data points, The first and second derivatives of the spline are continuous at the data points, ensuring smoothness. Lets try by scratch\nimport numpy as np import pandas as pd import matplotlib.pyplot as plt from scipy.interpolate import CubicSpline # Read Data data = pd.read_excel(\u0026#39;83MDR-5_c.xlsx\u0026#39;,sheet_name=\u0026#39;Sheet12\u0026#39;) konstan = data[\u0026#39;n\u0026#39;].values # Kolom nilai konstan x = data[\u0026#39;x\u0026#39;].values y = data[\u0026#39;y\u0026#39;].values # Titik yang ingin diinterpolasi (gap 1 untuk hasil halus) t_interp = np.arange(min(konstan), max(konstan) + 1, 1) # Interpolasi Spline Kubik untuk koordinat X dan Y spline_x = CubicSpline(konstan, x) # Interpolasi untuk X spline_y = CubicSpline(konstan, y) # Interpolasi untuk Y # Hasil interpolasi x_interp = spline_x(t_interp) y_interp = spline_y(t_interp) # Visualisasi plt.plot(x, y, \u0026#39;o\u0026#39;, label=\u0026#39;Data Asli\u0026#39;) # Titik Asli plt.plot(x_interp, y_interp, \u0026#39;-\u0026#39;, label=\u0026#39;Interpolasi Spline\u0026#39;) # Garis Interpolasi plt.legend() plt.grid(True) plt.xlabel(\u0026#39;X\u0026#39;) plt.ylabel(\u0026#39;Y\u0026#39;) plt.title(\u0026#39;Interpolasi Spline untuk Koordinat\u0026#39;) plt.show() # Menyimpan hasil interpolasi ke dalam CSV baru hasil_interpolasi = pd.DataFrame({\u0026#39;konstan\u0026#39;: t_interp, \u0026#39;x\u0026#39;: x_interp, \u0026#39;y\u0026#39;: y_interp}) hasil_interpolasi.to_csv(\u0026#39;hasil_interpolasi.csv\u0026#39;, index=False) print(\u0026#39;Interpolasi selesai. Hasil disimpan dalam file \u0026#34;hasil_interpolasi.csv\u0026#34;.\u0026#39;) Okay , we get the data but still problem with inteporlations like :\nInconsistent interval data like interval shot point should be getting consisntenly / appromaxiamtely 60m Same problems like before, we tried and got inconsitensly for near offset should be in 30 me between shot point and first receiver ","date":"1 March 2025","externalUrl":null,"permalink":"/projects/interpolations-coordinate/","section":"Projects","summary":"TIn the world of geophysics, coordinates are typically the foundation of all measurements and interpretations. They allow geophysicists to map subsurface features, such as faults, reservoirs, and layers, with precision.","title":"Interpolation coordinates Shot Point (SP) data as supported imaging seismic","type":"projects"},{"content":"","date":"1 March 2025","externalUrl":null,"permalink":"/tags/learning/","section":"Tags","summary":"","title":"Learning","type":"tags"},{"content":" Introduction # Seismic petrophysics inversion typically involves the prediction of subsurface properties like porosity and fluid volumes based on seismic data. Traditionally, this process involves multiple steps: first, inversion of seismic data to estimate velocities (through methods like acoustic inversion), and then using these velocities to predict petrophysical properties. The main limitation of these methods is that they often do not incorporate uncertainty quantification, leading to suboptimal predictions. Machine learning, and more specifically physics-informed neural networks (PINNs), offer an alternative by integrating data and physical models in the learning process, improving the estimation process. This paper aims to enhance this by introducing a probabilistic approach to PINNs.\nThe training will stop once the model reaches convergence, meaning the loss function is minimized to an acceptable level. If convergence is not achieved, the training process continues by further adjusting the model parameters.\nPINN Model Workflow: # Input Seismic Data (d): Observed seismic data is fed into the inverse model. Inverse Model: Estimates the petrophysical properties and rock-physics model parameters. Forward Model: Simulates seismic data (d̃) from the predicted properties. Loss Calculation: Calculates the seismic loss (Ls) and the property loss (Lp), and computes the total loss. Optimization: The model is optimized using the Adam optimizer to minimize the total loss. Training Loop: This process repeats until the model converges. This PINN framework ensures that the predicted seismic data aligns with actual seismic data and that the estimated petrophysical properties are realistic, constrained by physical laws (i.e., rock-physics models). The addition of probabilistic components can further help with uncertainty quantification, enhancing model robustness. import torch from torch.nn.functional import conv1d from torch import nn, optim import numpy as np from core.Inversion import * from core.RockPhysics import * from torch.nn.functional import pad device = \u0026#39;cuda\u0026#39; if torch.cuda.is_available() else \u0026#39;cpu\u0026#39; class inverse_model(nn.Module): def __init__(self, in_channels, resolution_ratio=4, nonlinearity=\u0026#34;tanh\u0026#34;): super(inverse_model, self).__init__() self.in_channels = in_channels self.activation = nn.Tanh() if nonlinearity == \u0026#34;relu\u0026#34; else nn.Tanh() self.c2 = 16 # 16 self.cnn1 = nn.Sequential(nn.Conv1d(in_channels=self.in_channels, out_channels=self.c2, kernel_size=11, padding=5, dilation=1), nn.BatchNorm1d(self.c2), self.activation) self.cnn2 = nn.Sequential(nn.Conv1d(in_channels=self.in_channels, out_channels=self.c2, kernel_size=11, padding=5, dilation=1), nn.BatchNorm1d(self.c2), self.activation) self.cnn3 = nn.Sequential(nn.Conv1d(in_channels=self.in_channels, out_channels=self.c2, kernel_size=11, padding=5, dilation=1), nn.BatchNorm1d(self.c2), self.activation) self.cnn = nn.Sequential(nn.Conv1d(in_channels=3 * self.c2, out_channels=3 * self.c2, kernel_size=11, padding=5, dilation=1), nn.BatchNorm1d(3 * self.c2), self.activation, nn.Conv1d(in_channels=3 * self.c2, out_channels=2 * self.c2, kernel_size=11, padding=5, dilation=1), nn.BatchNorm1d(2 * self.c2), self.activation, nn.Conv1d(in_channels=2 * self.c2, out_channels=2 * self.c2, kernel_size=11, padding=5, dilation=1 ), nn.BatchNorm1d(2 * self.c2), self.activation) self.gru = nn.GRU(input_size=self.in_channels, # 1 hidden_size=self.c2, # 4 num_layers=3, batch_first=True, bidirectional=True) self.up = nn.Sequential(nn.ConvTranspose1d(in_channels=2 * self.c2, out_channels=self.c2, stride=2, kernel_size=2, padding=1, dilation=3, output_padding=2), nn.BatchNorm1d(self.c2), self.activation, nn.ConvTranspose1d(in_channels=self.c2, out_channels=self.c2, stride=2, kernel_size=2, padding=1, dilation=3), nn.BatchNorm1d(self.c2), self.activation) self.gru_out = nn.GRU(input_size=self.c2, # hidden_size=self.c2, num_layers=1, batch_first=True, bidirectional=True) self.out = nn.Linear(in_features=2 * self.c2, out_features=self.in_channels) self.dropout = nn.Dropout(p=0.2) nnr = 10 # number of neuron 10 self.fc1 = nn.Linear(2,nnr) self.fc2 = nn.Linear(nnr, nnr) self.fc3 = nn.Linear(nnr,2) for m in self.modules(): if isinstance(m, nn.Conv1d) or isinstance(m, nn.ConvTranspose1d): nn.init.xavier_uniform_(m.weight.data) m.bias.data.zero_() elif isinstance(m, nn.BatchNorm1d): m.weight.data.fill_(1) m.bias.data.zero_() elif isinstance(m, nn.Linear): m.bias.data.zero_() self.optimizer = optim.Adam(self.parameters(), 0.005, weight_decay=1e-8) Inverse Model (Neural Network) # The inverse_model class is a neural network architecture designed for inverse seismic modeling. It attempts to learn the relationship between seismic data and petrophysical properties (like porosity, clay content, and water saturation).\nNetwork Components: # CNN Layers:\nThe network starts with three separate 1D convolution layers (cnn1, cnn2, cnn3), each with 16 channels, using a kernel size of 11. The convolution layers help extract high-level features from the seismic data by applying a sliding window (convolution) on the input data. These layers also include Batch Normalization to stabilize the learning process and an activation function (Tanh).\nConcatenation of CNN Outputs:\nThe outputs of the three convolution layers are concatenated and passed through another convolution layer, which combines these features to create a more comprehensive representation of the seismic data.\nGRU Layer:\nA Gated Recurrent Unit (GRU) layer processes the temporal or sequential aspects of the seismic data. GRUs are effective at learning dependencies over time, which is important for time-series data such as seismic traces.\nUpsampling (ConvTranspose):\nThe up layer consists of transpose convolution layers (also known as deconvolutions) that upsample the data to a higher resolution. This is done after the data has been processed through the GRU and CNN layers, improving its dimensionality and allowing for better feature reconstruction.\nOutput Layer:\nThe final output layer is a GRU followed by a fully connected (FC) layer that produces the final predicted seismic data (x) and other estimated petrophysical properties (z). The network also includes dropout regularization to prevent overfitting.\ndef forward(self, x,z): # x = pad(x, (1, 0), \u0026#34;constant\u0026#34;, 0) cnn_out1 = self.cnn1(x) cnn_out2 = self.cnn2(x) cnn_out3 = self.cnn3(x) cnn_out = self.cnn(torch.cat((cnn_out1, cnn_out2, cnn_out3), dim=1)) cnn_out = self.dropout(cnn_out) tmp_x = x.transpose(-1, -2) rnn_out, _ = self.gru(tmp_x) rnn_out = rnn_out.transpose(-1, -2) rnn_out = self.dropout(rnn_out) x = rnn_out + cnn_out x = self.up(x) x = self.dropout(x) tmp_x = x.transpose(-1, -2) x, _ = self.gru_out(tmp_x) x = self.out(x) x = x.transpose(-1, -2) z = self.fc1(z) z = self.dropout(z) z = self.fc2(z) z = self.dropout(z) z = self.fc3(z) z = torch.sigmoid(z) return x,z class forward_model(nn.Module): def __init__(self, resolution_ratio=4, ): super(forward_model, self).__init__() self.resolution_ratio = resolution_ratio # self.criticalporo = 0.4 # self.coordnumber = 7 def forward(self, y, criticalporo, coordnumber): # based on granular media theory+softsand+ aki-richard approximation, the shape of Phi,Vclay,Sw, should be [ns,nt] # m.shape = [nt,n,ns] # m[:,0] = Phi, m[:,1] = Vclay, m[:,2] = Sw, ## rock phsyics parameters # solid phase (quartz and clay) Kclay = 21 Kquartz = 33 Gclay = 15 Gquartz = 36 Rhoclay = 2.45 Rhoquartz = 2.65 # fluid phase (water and gas) Kwater = 2.25 Kgas = 0.1 Rhowater = 1.05 Rhogas = 0.1 patchy = 0 # granular media theory parameters # criticalporo = self.criticalporo # unknown parameters, reference value 0.4 # coordnumber = self.coordnumber # unknown parameters, reference value 7 pressure = 0.02 ## seismic parameters # angles theta = [15, 30, 45] # wavelet dt = 0.001 freq = 45 ntw = 64 wavelet, _ = RickerWavelet(freq, dt, ntw) # solid and fluid phases y = y[..., ::self.resolution_ratio] ns = y.shape[2] nt = y.shape[0] Phi = y[:, 0].T Vclay = y[:, 1].T Sw = y[:, 2].T Kmat = torch.zeros([ns, nt]) Gmat = torch.zeros([ns, nt]) Rhomat = torch.zeros([ns, nt]) Kfl = torch.zeros([ns, nt]) Rhofl = torch.zeros([ns, nt]) for i in range(nt): Kmat[:, i], Gmat[:, i], Rhomat[:, i], Kfl[:, i], Rhofl[:, i] = MatrixFluidModelTorch( torch.tensor([Kclay, Kquartz]), torch.tensor([Gclay, Gquartz]), torch.tensor([Rhoclay, Rhoquartz]), torch.hstack([Vclay[:, i].reshape(-1, 1), (1 - Vclay[:, i]).reshape(-1, 1)]), torch.tensor([Kwater, Kgas]), torch.tensor([Rhowater, Rhogas]), torch.hstack([Sw[:, i].reshape(-1, 1), (1 - Sw[:, i]).reshape(-1, 1)]), patchy) ## Density Rho = DensityModel(Phi, Rhomat, Rhofl) ## Soft sand model Vp, Vs = SoftsandModelTorch(Phi, Rho, Kmat, Gmat, Kfl, criticalporo, coordnumber, pressure) # Wavelet matrix nm = Vp.shape[0] ntheta = len(theta) W = WaveletMatrix(wavelet, nm, ntheta) W = torch.tensor(W).float() if torch.cuda.is_available(): W = W.cuda() ## Seismic Snear = torch.zeros([ns - 1, nt]) Smid = torch.zeros([ns - 1, nt]) Sfar = torch.zeros([ns - 1, nt]) for i in range(nt): Seis = SeismicModelAkiRichardTorch(Vp[:, i].reshape(-1, 1), Vs[:, i].reshape(-1, 1), Rho[:, i].reshape(-1, 1), theta, W) Snear[:, i] = Seis[:ns - 1].flatten() # ns-1 not include acorrding to python role Smid[:, i] = Seis[ns - 1:2 * (ns - 1)].flatten() Sfar[:, i] = Seis[2 * (ns - 1):].flatten() d = torch.stack([Snear, Smid, Sfar], axis=1) d = d.permute(*torch.arange(d.ndim - 1, -1, -1)) # SeisSyn = d[..., ::self.resolution_ratio] return d Forward Model (Seismic Simulation) # The forward_model class is responsible for simulating seismic data based on input petrophysical properties (y) and rock physics parameters (e.g., porosity, clay content, water saturation). It models the process of generating seismic data from physical rock properties.\nModel Components: # Rock Physics Model:\nThe class contains physical constants for rock and fluid properties, including bulk modulus, shear modulus, density, and porosity. It uses the granular media theory and other rock physics models to simulate how seismic waves propagate through the medium.\nSeismic Data Generation:\nThe class includes a section for generating synthetic seismic data using the Aki-Richards model. The seismic data (d) is generated for different angles (denoted as theta) and uses a Ricker wavelet as the source signal.\nDensity and Velocity Models:\nThe model computes density (Rho), velocity (Vp, Vs), and other key petrophysical properties based on the provided rock physics parameters (e.g., critical porosity, coordination number, **pressure).\nSeismic Simulation:\nIt generates seismic data (d) by simulating the seismic wave propagation through the medium. The synthetic seismic data is split into three different zones (near, middle, far) based on the angle of incidence. The seismic data (d) is then assembled into a final tensor representing the full synthetic dataset.\nForward Method: # The forward() method takes the input y (which contains properties such as porosity, clay volume, and water saturation) and computes the seismic data using rock physics and the granular media theory. The model computes the seismic responses for different angles and stores them in a matrix d. This simulated data is then returned.\nSummary of the Models\u0026rsquo; Purpose: # Inverse Model:\nThe inverse_model class learns to predict the petrophysical properties (like porosity, water saturation) from seismic data using deep learning. It combines CNNs and GRUs to extract and process the features in the seismic data, then uses upsampling to refine the output.\nForward Model:\nThe forward_model class generates synthetic seismic data from petrophysical properties using rock physics models. It calculates the seismic response using physical parameters such as density, porosity, and fluid content. The synthetic seismic data is used to train the inverse model.\nBut, currently still developing for cases in Indonesia field . we used code by scratch from KAUST lab computation geophysics. However after this we tried and ran this program to know about the process between seismic and petrophysical inversion to tackle complex geophyical. We try and using HPC cluster with NVIDIA GPU for running 500 epoch almost 93 hours.\n","date":"1 March 2025","externalUrl":null,"permalink":"/projects/pinn-models/","section":"Projects","summary":"Traditionally, this process involves multiple steps: first, inversion of seismic data to estimate velocities (through methods like acoustic inversion), and then using these velocities to predict petrophysical properties. The main limitation of these methods is that they often do not incorporate uncertainty quantification, leading to suboptimal predictions. Machine learning, and more specifically physics-informed neural networks (PINNs).","title":"Learning PINN Models for cases in between seismic data and well logs data","type":"projects"},{"content":"","date":"1 March 2025","externalUrl":null,"permalink":"/tags/paper/","section":"Tags","summary":"","title":"Paper","type":"tags"},{"content":"","date":"1 March 2025","externalUrl":null,"permalink":"/categories/post/","section":"Categories","summary":"","title":"Post","type":"categories"},{"content":"","date":"1 March 2025","externalUrl":null,"permalink":"/categories/projects/","section":"Categories","summary":"","title":"Projects","type":"categories"},{"content":"","date":"1 March 2025","externalUrl":null,"permalink":"/tags/seismic/","section":"Tags","summary":"","title":"Seismic","type":"tags"},{"content":"","date":"1 March 2025","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"1 March 2025","externalUrl":null,"permalink":"/tags/technical/","section":"Tags","summary":"","title":"Technical","type":"tags"},{"content":" Problem # Extracting text from an image can be exhausting, especially when you have a lot to extract. One commonly known text extraction library is PyTesseract or EasyOCR, optical character recognition (OCR). These libraries provide you with the text directly from the image.\nWhen dealing with engineering or technical documents, like the one in this image, OCR tools can help quickly digitize content, which would otherwise require manual input. In this case, you can see a list of static corrections related to well logging or seismic corrections. The image includes various measurements such as elevation, charge, and V-corrections, commonly seen in geophysical data records.\nImagine having to manually extract and process hundreds or even thousands of images, each containing complex, tabulated data. Just think about it—over 100+ images of similar data that need to be converted into Excel sheets for further analysis or reporting. Without the help of OCR tools, this process would take days, if not weeks, of painstakingly typing out each value. But with OCR, what would have been a monumental task turns into a much more manageable job. The text extraction happens almost instantly, and the data is ready for further processing, analysis, or integration into reports.\nOCR tools are especially helpful in industries like oil and gas, where seismic logs, drilling reports, and other technical documents are generated constantly. For example, if you\u0026rsquo;re dealing with 100+ images of seismic data, you can automate the process, convert it to text, and then easily export it to an Excel sheet, making further analysis and visualization far easier and faster. What would’ve been an entire week’s worth of manual labor becomes a few minutes of processing.\nYou can look how many row and coloumn to convert from images to excel. It\u0026rsquo;s so wasting time and that\u0026rsquo;s why i need to solve the problem with using OCR\nGetting Started # When I write an algorithm, I always try to think of it like I’m teaching it the way humans naturally process information. This approach helps me break down complex ideas into simpler, more digestible steps. It’s like guiding someone through a process in the most intuitive way possible.\nTake reading a table, for example. The first thing that catches your attention is usually the cells. These cells are like the building blocks of the table, neatly organized, waiting to be explored. You might notice that the cells are separated by borders—these borders can be either vertical or horizontal, providing structure and organization to the data. Once you identify these cells, you’re ready to dive deeper and understand the information contained within each one.\nNow, let\u0026rsquo;s break this process down into an algorithm. I imagine it like this: first, cell detection, where the algorithm identifies each individual cell—just like how your eyes recognize the compartments of the table. Where the algorithm selects the part of the table that holds the information we want to extract, much like you would focus on a specific section of the table. Finally, text extraction happens, where the algorithm pulls out the data from each selected region, transforming the visual information into usable text.\nExample Python Code # import cv2 import numpy as np from matplotlib import pyplot as plt # Load the image image = cv2.imread(\u0026#34;/content/page_27.png\u0026#34;) # Replace with your image file path # Convert to grayscale gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # Sharpen the image using a kernel sharpen_kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]]) sharpen = cv2.filter2D(gray, -1, sharpen_kernel) # Apply Otsu\u0026#39;s thresholding thresh = cv2.threshold(sharpen, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1] # Show the result plt.imshow(thresh, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Thresholded Sharpened Image\u0026#39;) plt.show() By thinking of the process this way, it becomes easier to translate human intuition into precise, step-by-step instructions for the algorithm to follow. This approach creates an algorithm that doesn’t just \u0026ldquo;work\u0026rdquo;—it mimics the way we naturally process and understand information, making it both powerful and intuitive.\nfor item in r_easy_ocr: try: value = int(item) # Try to convert the item to an integer if value \u0026gt; 1000: if current_row: processed_data.append(current_row) current_row = [value] else: current_row.append(item) except ValueError: current_row.append(item) # Keep non-numeric values in the current row # Add the last row if it\u0026#39;s not empty if current_row: processed_data.append(current_row) # Create a DataFrame from the processed data df_processed = pd.DataFrame(processed_data) # Save the DataFrame to a different sheet in one Excel file sheet_name = os.path.splitext(image_file)[0] # Use image name as sheet name df_processed.to_excel(writer, sheet_name=sheet_name, index=False) Processing OCR Results and Identifying SP Numbers # When working with OCR (Optical Character Recognition) results, especially for structured data such as tables, it’s essential to organize the data in a way that makes it easier to analyze. In this case, the goal is to identify and separate unique SP numbers—values greater than 1000—from other data in the image. Here’s how the algorithm works:\nIterating through the OCR results:\nThe r_easy_ocr variable likely contains a list of text data extracted from an image using OCR. This loop goes through each item in the OCR results and processes them one by one.\nIdentifying Unique SP Numbers (greater than 1000):\nEach item in the list is first checked to see if it can be converted into an integer using int(item). If the conversion is successful, the code checks if the resulting value is greater than 1000. In this case, numbers greater than 1000 are treated as unique SP numbers, which are used as identifiers for a new row in the data. This ensures that any SP number, which is a key identifier, is treated separately from other values.\nGrouping Data by SP Number:\nOnce an SP number is found, it signifies the start of a new \u0026ldquo;row\u0026rdquo; in the data. The current row is appended to the processed_data list (if it isn’t empty), and a new row starts with the unique SP number. Any subsequent values that don’t meet the condition of being greater than 1000 are grouped into the current row until another unique SP number is encountered.\nHandling Non-Numeric Values:\nIf the item cannot be converted into a number (e.g., text), it is appended to the current row as-is. This ensures that textual information or other non-numeric values are still captured and stored in the same row as the associated SP number.\nFinalizing the Rows:\nAfter the loop finishes, any remaining data in current_row is added to processed_data. This step ensures that the last set of data is also included in the result, even if there wasn’t another unique SP number to trigger its addition.\nCreating the DataFrame:\nThe processed data is then converted into a Pandas DataFrame. This allows for easy organization and manipulation of the data, especially when dealing with tabular OCR results.\nSaving the Data:\nThe final DataFrame is saved to an Excel file. Each image processed generates a separate sheet, with the name of the sheet corresponding to the image file name (without the file extension). This ensures that the data from each image is stored in its own sheet for easy reference.\nKey Takeaways: # Unique SP Numbers: The algorithm is specifically designed to treat values greater than 1000 as unique identifiers (SP numbers) that separate different data entries, helping to maintain the integrity of the data. Row Grouping: Values associated with each SP number are grouped into rows, ensuring that related data stays together. Non-numeric values are handled gracefully without breaking the flow. Excel Output: The processed data is output to an Excel file, where each image’s data is stored in its own sheet for further analysis or reporting. This approach ensures that the OCR data is well-structured, and key identifiers (SP numbers) are captured and used to organize the data effectively.\nThis is the resulted after OCR\nResults and Next Steps for Improvement # The algorithm successfully groups the OCR results into meaningful rows, using SP numbers (values greater than 1000) as unique identifiers. This approach effectively organizes the data and ensures that related information is stored together. However, after analyzing the results, there are a few areas where improvements can be made:\nAccuracy of OCR Output:\nThe OCR process itself sometimes fails to capture numbers accurately, especially in images with poor quality or complex layouts. In some cases, OCR errors led to incorrect SP number identification or missing data. To address this, we can experiment with different OCR libraries (like Tesseract or EasyOCR) and fine-tune the preprocessing steps (such as denoising, adjusting image contrast, etc.) to improve the recognition accuracy.\nHandling Multiple SP Numbers in Close Proximity:\nIn some cases, multiple SP numbers appeared close together, which may have caused the algorithm to misidentify data boundaries. A more sophisticated method of detecting and separating closely spaced SP numbers could help improve the results. For example, using image segmentation or adjusting the threshold for what constitutes an SP number could make this process more reliable.\nImproving Data Grouping Logic:\nWhile the current approach groups values into rows based on SP numbers, some edge cases—such as rows that span across multiple SP numbers or have multiple values greater than 1000—were not handled as expected. Future iterations could involve refining the logic to better capture these edge cases and ensure more accurate grouping of data.\nHandling Special Cases:\nText-based values and annotations, while being correctly appended to rows, sometimes disrupted the flow of numerical data. Implementing a more nuanced approach to separate numeric data from textual information (e.g., using regular expressions to identify and categorize data types) could improve the final output.\nKey Takeaways: # Unique SP Numbers: The algorithm effectively identifies SP numbers greater than 1000, treating them as unique row identifiers, which helps organize the data. Grouping and Row Management: Non-numeric values are handled appropriately, and the algorithm correctly groups related data under the right SP number. Areas for Improvement: Improving OCR accuracy, handling edge cases, and refining data grouping logic will lead to more reliable results in the future. This approach provides a solid foundation for processing OCR results. However, as with any machine learning or OCR-based system, continuous improvement is necessary to handle new data variations and achieve higher accuracy. The next steps will focus on refining the algorithm, ensuring better handling of edge cases, and enhancing the overall performance of the OCR process.\n","date":"1 March 2025","externalUrl":null,"permalink":"/projects/text-extraction-from-images/","section":"Projects","summary":"Extracting text from an image can be exhausting, especially when you have a lot to extract. One commonly known text extraction library is PyTesseract or EasyOCR, optical character recognition (OCR). These libraries provide you with the text directly from the image.","title":"Text Extraction from Image in this case Document Report Seismic","type":"projects"},{"content":"","date":"15 September 2024","externalUrl":null,"permalink":"/tags/competitions/","section":"Tags","summary":"","title":"Competitions","type":"tags"},{"content":" Background # The focus of this presentation is how to utilize seismic data to predict gamma-ray logs or GR. These predictions play an important role in identifying lithologic characteristics, stratigraphy, sedimentary facies and hydrocarbon zones, especially in exploration areas that lack well data. However, the main challenge is the limited resolution of seismic data, which makes it difficult to identify thin layers or complex structures.\nTo develop a machine learning model that can accurately predict gamma-ray logs from 3D seismic data Solving the limitations of seismic resolution by applying machine learning techniques that are able to identify complex patterns between seismic data and GR logs This aims to provide more accurate predictions in areas with limited well data. Main # This study adopted machine learning and deep learning approaches\nCNN Models Random Forest K-Nearest Neighbour Retrieve opensource data from the web https://terranubis.com/datainfo/F3-Demo-2023 owned by OpendTect project with 3D Seismic Data, Acoustic Impedance, Wells, Horizons. Then the data is selected and processed to become seismic attribute data. We were using seismic attirbute such as:\nChaos RMS Amplitudo Envelope Gradient Magnitude Sweetness Instaneous Frequency Dominant Frequency Instaneous Quality Instaneous Bandwith After that, we continued to convert 3D Seismic data to only 1D data because how to know about correlations between trace data nearby from well logs. you can see image below, In this case, we’re predicting the GR log using post-stack seismic data. The lithology log has been converted to traveltime, matching the 2 ms sample rate of the seismic data. Getting the depth-to-time conversion right is super important because it directly impacts accuracy. CNNs have been widely used for solving different problems like image classification and speech recognition. In image classification, images are treated as 2D or 3D matrices, while in speech recognition, sound waves are converted into time-frequency spectra, which are then processed using convolution operations.\nJust like sound wave spectra, seismic traces can also be transformed into time-frequency spectra. One way to do this is by using Continuous Wavelet Transforms (CWTs), which help analyze frequency variations in seismic data. These variations are key to detecting subtle changes in subsurface features, especially in thin layers. Since a CWT-generated seismic trace can be represented as a 2D map, it’s a great fit as an input for CNNs. After that based on correaltios matirix you can look image below to use everything logs because showing value correlations \u0026lt;0.5\nValue from this cases # The estimated cost of conducting a 3D seismic acquisition for 20 km² is approximately $1 million, while drilling a single well to a depth of 2 km costs approximately $700,000. Consequently, drilling is a costly and uncertain endeavor. To achieve the most optimal Gamma Ray Log results, predictions in the form of pseudo log data are utilized. One main Random Forest Regressor model, ExtraTree Regressor and CNN Model + LSTM 1D for the best prediction accuracy of the three models. Models are updated periodically when new data becomes available (e.g., after new seismic surveys, additional wells are drilled, different study area).\nAt the start, the CNN-LSTM model was trained with default hyperparameters. As you can see from the graphs, the training loss (blue line) decreases quickly, suggesting the model is learning well on the training data. However, the validation loss (orange line) shows a very different behavior, which indicates underfitting—the model isn\u0026rsquo;t generalizing well to new, unseen data. This is reflected in the large gap between the training and validation metrics. The Mean Squared Error (MSE) and Mean Absolute Error (MAE) values are high, with the MSE being over 1,100 and MAE being above 29.\nAnother key point is the R² score, which is negative (around -3.77). This means the model is performing worse than a simple mean-based baseline, indicating a serious problem in prediction quality. The high discrepancy between train and validation losses implies that the model has failed to capture important features of the validation data.\nThis early stage reflects that the model is too simple or poorly tuned for the task, causing poor performance on validation data. It’s not yet ready to make reliable predictions.\nAfter adjusting the model\u0026rsquo;s hyperparameters and re-training, things improved significantly. As shown in the graphs, the training loss (blue) and validation loss (orange) are now much closer to each other, indicating that the model is generalizing better and has moved away from underfitting. While there\u0026rsquo;s still some fluctuation, it’s not as severe as in the previous model.\nWith this fine-tuned version, the MSE has dropped to about 737, and the MAE has decreased to approximately 23, showing a significant improvement in prediction accuracy. Although there\u0026rsquo;s still a gap between training and validation metrics, the overall trend indicates that the model is learning more effectively and predicting with greater accuracy.\nThe R² score also improved, though it’s still negative, which suggests the model is still underperforming relative to a baseline but is certainly better than before. There’s still room for improvement, especially in terms of reducing validation loss fluctuations, but fine-tuning the hyperparameters has made the model much more robust and effective than the initial version.\nThe learning curve shown in the graph demonstrates the performance of the Bagging Regressor model with respect to the number of training instances you can see with two lines blue and green. This learning curve suggests that the Bagging Regressor is performing well on both the training and validation data, demonstrating solid generalization capability, which is likely due to the cross-validation process used by PyCaret.\nActual vs Predicted Depth Comparison # The following plots compare the actual vs predicted depth (GR) values for three different models. Each plot shows the performance of the model in predicting depth based on the given dataset:\n1. CNNID + LSTM Model (Left Plot) # Blue Line (Actual): Represents the actual depth values from the dataset. Orange Line (Non-Tuned Predictions): Shows the predictions made by the CNNID + LSTM model before hyperparameter tuning. There is noticeable deviation from the actual values, indicating that the model needs further refinement. Green Line (Tuned Predictions): After fine-tuning, this line represents the predictions of the CNNID + LSTM model. While there is still some deviation, the green line is closer to the actual values compared to the orange line, indicating that tuning improved the model\u0026rsquo;s performance, though it\u0026rsquo;s still not perfect. 2. Extra Tree Regressor (Middle Plot) # Blue Line (Actual): As in the previous plots, the blue line represents the true depth values. Green Line (Predictions): This line shows the predictions from the Extra Tree Regressor. Compared to the CNNID + LSTM model, the predictions from the Extra Tree Regressor are much closer to the actual values, demonstrating a better fit to the data with less deviation. 3. Random Forest Regressor (Right Plot) # Blue Line (Actual): The true depth values are represented by the blue line. Green Line (Predictions): The green line shows the predictions from the Random Forest Regressor. Similar to the Extra Tree Regressor, the Random Forest model\u0026rsquo;s predictions are very close to the actual values, indicating high accuracy and a strong predictive ability. Summary # The CNNID + LSTM model shows improvement after hyperparameter tuning but still has noticeable gaps compared to the actual values, suggesting that it could benefit from further optimization. Both the Extra Tree Regressor and Random Forest Regressor show better performance, with predictions much closer to the actual values. These models provide more stable and accurate results compared to the CNNID + LSTM model. In conclusion, the tree-based models (Extra Tree and Random Forest) appear to outperform the CNNID + LSTM model for this particular task. Deploy # After deployment, the performance of the system is evaluated using existing data. Metrics such as MSE, MAE, R², RMSLE, and MAPE are monitored to ensure the accuracy and reliability of the system. We choose data testing in well F-06 you can see the table like that :\nThe table below presents the performance metrics for the Random Forest Regressor model:\nModel MAE MSE RMSE R2 RMSLE MAPE Random Forest Regressor 1.7372 9.5825 3.0956 0.9838 0.0803 0.0470 Metric Descriptions: # MAE (Mean Absolute Error): The model\u0026rsquo;s average error magnitude is 1.7372, which shows the average difference between the predicted and actual values. MSE (Mean Squared Error): The squared average of the errors is 9.5825, which gives an idea of the variance of the model errors. RMSE (Root Mean Squared Error): The square root of MSE is 3.0956, providing a more interpretable scale of the error. R² (R-Squared): This value is 0.9838, indicating that the model explains 98.38% of the variance in the data, demonstrating excellent fit. RMSLE (Root Mean Squared Logarithmic Error): The RMSLE is 0.0803, which is typically used for data that involves exponential growth. MAPE (Mean Absolute Percentage Error): With a value of 0.0470, this represents the model\u0026rsquo;s prediction After this the result like this :\nConclusions # The findings of this research suggest that ML techniques, particularly Random Forest, CNN, can significantly enhance the prediction of GR logs from seismic data, providing a valuable tool for subsurface characterization in hydrocarbon exploration. This approach can be used as a benchmark for future studies and field development\n","date":"15 September 2024","externalUrl":null,"permalink":"/projects/deep-learning-approaches/","section":"Projects","summary":"The focus of this presentation is how to utilize seismic data to predict gamma-ray logs or GR. These predictions play an important role in identifying lithologic characteristics, stratigraphy, sedimentary facies and hydrocarbon zones, especially in exploration areas that lack well data.","title":"Deep Learning Approaches for seismic GR Predictions: insight from seismic attributes","type":"projects"},{"content":" Abstract # The oil and gas industry produces an immense quantity of complex data, including geological, seismic, and well log data. Machine learning can overcome the challenge of identifying trends that are difficult to recognize using conventional techniques. A well log, which contains subsurface information, is one of the most massive and complex types of data. The difficulty in this data processing originates from some intervals that experience data loss or drilling issues. The study used machine learning approaches to acquire predictive log Gamma Ray (GR) data by evaluating the window time base and applying machine learning algorithm in the form of Random Forest and K-Nearest Neighbor (KNN), also deep learning Long-Short Term Memory (LSTM) and Bi-LSTM. The field data utilized for the evaluation of each algorithm model is the Central Sumatra Basin. Following this, classification metrics are used to validate the test results of the algorithm, which yields an accuracy greater than 80% and the smallest mean absolute error (MAE) value. This validation provides an optimal score that can be used for empirical decision-making, giving priority to data with strong correlations. This research examines each model algorithm\u0026rsquo;s ability to be proposed in a predictive analysis of well-logged data imputation rapidly and accurately.\nMain # In this research, we tried out several machine learning (ML) techniques to estimate missing log data, including Random Forest (RF), K-Nearest Neighbour (KNN), and deep learning models like Long Short-Term Memory (LSTM) and Bi-LSTM. Studies (Akinyemi et al., 2023; Feng et al., 2021; Gavidia et al., 2023) suggest that Random Forest works well, especially when the data range is more limited, leading to more accurate predictions. LSTM, on the other hand, is great at handling sequential data, allowing it to make predictions based on how information changes over time (Antariksa et al., 2023; Chakraborty et al., 2024; Zhang et al., 2024). Bi-LSTM takes it a step further by capturing complex temporal relationships in time series data, improving accuracy by analyzing the entire sequence (Cheng et al., 2022; Nath et al., 2022). Meanwhile, KNN is a simple yet effective non-parametric method that delivers solid classification results without making assumptions about data distribution. The catch? Choosing the right k value is crucial to getting the best classification performance (Kadri et al., 2022; Wood, 2020; Zhang et al., 2022).\nWe use log data from the Sintong field in the Central Sumatera Basin, covering depths from 500 to 3,240 meters. The dataset includes well logs like caliper (CAL), gamma ray (GR), self-potential (SP), and density (RHOB). After that we used correlation each other well and give the result GR and SP have the highest value but still low correlations (not too much strong)\nand after that we provide to normalziation data before training model\nwe separated 3 sections in each log for testing the model after that Table 1 shows the machine learning models optimized for prediction accuracy using GridSearch CV, which fine-tunes hyperparameters for both models. The Random Forest model uses 500 trees, while the KNN model is set to a maximum of 11 neighbors.\nMachine Learning Architecture Models # Machine Learning Architecture Models Models Random Forest KNN Depth 4-12 - Neighbors - 3-11 Weights - Uniform, Distance Estimators 100-500 - Features Auto, Square, Log - Time 28 Minutes 42 Seconds Table 2 presents the deep learning models, including the parameters for LSTM and Bi-LSTM. We tested both models with different activation functions—ReLU and TanH. These activation functions play a crucial role in forecasting time-series values, with TanH outperforming the other two deep-learning models.\nDeep Learning Architecture Models # Deep Learning Architecture Models Parameter LSTM Bi-LSTM Layers 32-256 64-128 Activations ReLU TanH Dropout 0.1–0.2 0.1–0.2 Epochs 250 250 Dense Layers 100 64 Result # Machine Learning Results # Among the machine learning models, KNN performed better than Random Forest in both speed and accuracy. It outshined Random Forest in making precise predictions. Shows the Blind Test results, where test data is split into three periods. The KNN model consistently delivered solid predictions across these time frames.\nML Model Performance Metrics # ML Model Data MAE MSE RMSE R² Score Random Forest Validation 10.48 216.04 14.7 0.78 Test 16.47 514.65 22.68 0.14 KNN Validation 7.63 181.25 13.46 0.822 Test 17.67 578.33 24.04 0.004 Deep Learning Results # For deep learning, both LSTM and Bi-LSTM (trained for 250 epochs) gave promising results. The model curve shows they converged well, with the lowest loss values at 0.3182 and 0.3136. Different activation functions were tested to optimize specific metric values. The Bi-LSTM model, in particular, showed lower RMSE and a solid R² score when using land activation. Both LSTM and Bi-LSTM excel at capturing complex patterns and trends in data, especially when dealing with nonlinear relationships and intricate data structures.\nDL Model Performance Metrics # DL Model Data MAE MSE RMSE R² Score LSTM Validation 0.3192 0.2484 0.4984 0.7536 Test 21.68 802.48 28.32 0.23 Bi-LSTM Validation 0.3136 0.234 0.4837 0.7679 Test 21.00 780.01 27.92 0.32 Conclusion # This study looks at how well two Machine Learning models (Random Forest and KNN) and two Deep Learning models (LSTM and Bi-LSTM) perform in predicting missing well log data, especially Gamma Ray. We evaluate each model using metrics like Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), Mean Squared Error (MSE), and R² score.\nIn the well log test, KNN outperformed Random Forest, delivering a higher R² score and lower RMSE when predicting well log values. On the deep learning side, Bi-LSTM did better than LSTM in terms of R² score and RMSE, mainly due to differences in activation functions. That said, both models are great at identifying complex patterns and trends in data with nonlinear relationships.\n","date":"17 May 2024","externalUrl":null,"permalink":"/projects/comparative-algorithm-ml/","section":"Projects","summary":"The study used machine learning approaches to acquire predictive log Gamma Ray (GR) data by evaluating the window time base and applying machine learning algorithm in the form of Random Forest and K-Nearest Neighbor (KNN), also deep learning Long-Short Term Memory (LSTM) and Bi-LSTM.","title":"Comparative Algorithm Machine Learning","type":"projects"},{"content":" Introduction # In the exploration and exploitation of hydrocarbons, various interdisciplinary studies are conducted and analyzed comprehensively to obtain as much information as possible about the physical properties and geometry of reservoir rocks beneath the surface. One of the key fields in this endeavor is geophysics, which plays a significant role in understanding subsurface structures. One of the most widely used geophysical methods is seismic reflection, which has been instrumental for decades in the global exploration of hydrocarbons.\nThe process of seismic data interpretation involves determining fault planes on 2D/3D seismic profiles, a task that typically requires considerable time and can be subject to uncertainty when performed manually using available software. This research focuses on using artificial intelligence, specifically Convolutional Neural Networks (CNN), to assist in the interpretation of seismic faults. The goal is to increase the efficiency of fault structure identification, providing better results in a shorter time frame.\nThe use of machine learning techniques, especially deep learning, has become more prevalent in recent years. In the early stages, traditional machine learning theories were employed to predict fault structures on seismic profiles, but these methods have evolved over time. In the 2010s, deep learning methods, such as CNN, have been utilized to tackle the complexities of fault identification with greater precision.\nSeismic faults are significant in the context of hydrocarbon traps. These faults can act as barriers or migration pathways for hydrocarbons, influencing the formation of oil and gas reservoirs. By applying deep learning with CNN, this research aims to improve the analysis and identification of seismic fault structures more effectively and efficiently. The intention is to reduce the time needed to identify faults from raw seismic data and minimize biases introduced by human interpretation.\nThis study\u0026rsquo;s research problem can be summarized into several key aspects:\nThe application of deep learning using the Extract, Transform, and Load (ETL) pipeline on 2D seismic data. The preprocessing of training data to classify fault structures in seismic data. The design and use of a U-Net deep learning architecture to optimally classify fault structures. A comparison of fault interpretation results between manual methods and deep learning techniques. The primary objective of this research is to identify fault structures both conventionally and through deep learning, assessing the effectiveness of fault labelling and predicting fault zones with high accuracy using deep learning techniques. Through this process, the study intends to demonstrate that deep learning can significantly improve the speed and precision of fault identification, offering valuable insights for the petroleum industry.\nMethodology # This study was conducted between December 2021 and December 2022 at the Institut Teknologi Sumatera, Lampung Selatan. The research methodology involved several critical steps to analyze seismic data and detect fault structures efficiently:\nData Collection: Seismic data from the F3 block in the North Sea was used, with a focus on 2D seismic profiles from inline 200 to 600. Data Preprocessing (ETL): The Extract, Transform, Load (ETL) process was applied to clean and prepare the seismic data, enabling it for further analysis. Wavelet Extraction: A wavelet extraction technique was used to generate synthetic seismograms, which helped in understanding the seismic data’s underlying features and structure. Well-Seismic Tie: The study integrated borehole data with seismic data to align geological and geophysical information, which is crucial for accurate depth determination in seismic profiles. Fault Picking: The study compared traditional manual fault picking methods with automated fault detection using deep learning techniques, with an emphasis on efficiency and accuracy. Deep Learning Model: The deep learning model used the U-Net architecture, a convolutional neural network (CNN), to perform segmentation and classification of seismic fault structures, offering a promising alternative to manual methods. Results and Discussion # The results from the application of deep learning to seismic data were analyzed and compared with traditional methods to assess the efficacy of automated fault detection.\nWell-Seismic Tie: The results indicated a high correlation (greater than 0.6) between the well data and seismic data, ensuring a reliable well-seismic tie. Picking Faults: Automated fault picking using deep learning showed superior performance in terms of speed and accuracy when compared to manual picking, making the process much more efficient. ETL and Training: The data preprocessing using the ETL pipeline involved creating labeled seismic images, which were then split into 80% for training and 20% for validation. This process significantly improved the model’s predictive accuracy. Confusion Matrix and Model Performance: The performance of the deep learning model was evaluated through a confusion matrix, where the model showed high precision and recall values, demonstrating its effectiveness in fault detection. Model Comparison: A direct comparison between manual and automated methods highlighted the advantages of using deep learning, which resulted in faster and more accurate fault detection from seismic data. These two chapters provide an in-depth discussion of the methodology used and the results obtained, demonstrating the potential of deep learning techniques to revolutionize the seismic fault interpretation process.\nImages 1: Well-seismic tie process for well F06-1, showing synthetic seismogram and correlation results. Images 2: Train Data on inline 300. Images 3: Conventional picking result on inline 300 using basemap. Images 4: Fault labelling using Inscape tools on inline 200 and result. Images 4: Confusion Matrix. Precision Recall F1-Score Support No Fault 1.00 0.99 0.99 3842 Fault 0.85 0.93 0.89 254 Visit Full My Thesis to know full my thesis\n","date":"17 March 2023","externalUrl":null,"permalink":"/projects/fault-detection/","section":"Projects","summary":"In the exploration and exploitation of hydrocarbons, various interdisciplinary studies are conducted and analyzed comprehensively to obtain as much information.","title":"Seismic Fault Interprattion Using Deep Learning: Convolutional Neural Network (CNN)","type":"projects"},{"content":"","date":"13 June 2022","externalUrl":null,"permalink":"/projects/","section":"Projects","summary":"","title":"Projects","type":"projects"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":" Full My CV # Grab my full CV to press the button at the below :\nDownload\nExperience # \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e\rBBPMGB LEMIGAS Feb 2023 to Present Junior Geophysicist Processing and Interpreter Seismic Website\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?\u003e PT Fifan Oct 2023 to Jan 2024 Geophysicist Conducting underwater magnetic data collecting, Sub-Bottom Profile (SBP) and Side Scan Sonar(SSS) Website\nBangkit Academy by Google,GoTo,Traveloka Feb 2023 to Jan 2024 Machine Learning Mentor Monitoring progress mentee and remind again about system and technical learning Website\nBangkit Academy by Google,GoTo,Traveloka Feb 2022 to Jul 2022 Machine Learning Path Student Internship Created capstone project about Smart Traffic: Vehicle Count using Tensorflow, YoloV3 models, how to manage a team (5 people), time well and responsible for end-to-end development of machine learning algorithms (clustering, decision tree, etc). Website\nEducations # EF EFEKTA Jan 2024 to Mar 2025 English Student Learning English to improve such as speaking, listening , reading and writing\nDownload Institut Teknologi Sumatra Aug 2018 to Mar 2023 Bachelor Degree, Geophysics Engineering Learning GnG Conceptual, using Machine learning and Deep learning to Automatic Interpretation of Seismic Fault\nAwards/Honor: Sinta 2 for thesis topic\nRelevant Coursework: Python, Machine Learning, Deep Learning, GIS, Seismic Interpretation/Processing, Mapping\nThesis: Interpretation Of Seismic Fault Using Deep Learning Convolutional Neural Network (CNN) With U-Net Architectural Model in Block F3 North Sea, Netherlands\nDownload Publications # Journal papers # Saputra, N., Handoyo, H., Putri, I. A. (2023). “Interpretasi Sesar Geologi Menggunakan Deep Learning: Convolutional Neural Network (CNN) dengan Model Arsitektur U-Net di Laut Utara, Belanda”. In:Vol 9, No 3. [DOI] Conference proceedings # Saputra, N., Rohman, H.R.N., Alifya, P., Aprina, P.U. (2024). “Comparative Algorithm Machine Learning Approaches for Predictive Analysis Of Well Log Data Imputation In The Oil And Gas Industry: A Case Study In The Central Sumatra Basin.\u0026quot; Indoesian Petroleum Association (IPA) Convex and Exhibition. [Link] Skills # Geology and Geophysicist Oil and Gas Optimisation Machine learning algorithms Mathematical modelling Numerical methods Data analysis and visualisation Technologies # Geosciences Tools \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e\rQGIS/ArcGIS \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e\rPetrel \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e\rParadigm \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e\rProMax \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e\rOasis Montaj Software development Python Git \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e\rgithub\rGitHub Machine learning NumPy Pandas Scikit-learn PyTorch Visualisation Matplotlib Plotly Streamlit Cloud Docker GCP AWS ","externalUrl":null,"permalink":"/cv/cv/","section":"Cvs","summary":"Full My CV # Grab my full CV to press the button at the below :\nDownload\nExperience # \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e\rBBPMGB LEMIGAS Feb 2023 to Present Junior Geophysicist Processing and Interpreter Seismic Website","title":"Curriculum vitae","type":"cv"},{"content":"","externalUrl":null,"permalink":"/cv/","section":"Cvs","summary":"","title":"Cvs","type":"cv"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]